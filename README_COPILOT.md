# ğŸ™ï¸ Meeting Copilot

> AI-powered voice assistant for meetings with wake word detection, real-time transcription, and intelligent responses.

**Developed by:** Ruslan Magana
**Contact:** contact@ruslanmv.com

---

## âœ¨ Features

- ğŸ¤ **Multi-source audio capture**: Microphone, system audio (meetings), or both
- ğŸ‘‚ **Voice Activity Detection (VAD)**: Intelligent speech segmentation
- ğŸ”Š **Wake word activation**: Say "Watson" (configurable) to activate
- ğŸ“ **Real-time transcription**: IBM Watson Speech-to-Text
- ğŸ¤– **AI responses**: Powered by OpenAI GPT models
- ğŸ’¬ **Multiple modes**: Answer questions, give opinions, or summarize discussions
- ğŸ—£ï¸ **Text-to-Speech**: Natural voice responses (Edge TTS or IBM Watson)
- ğŸ–¥ï¸ **Desktop UI**: Professional PySide6 interface
- ğŸ”’ **Privacy-first**: Opt-in logging with encryption
- âš¡ **Low latency**: < 2.5s wake-to-response target

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Windows** (recommended for system audio capture via WASAPI)
- **uv** package manager (auto-installed by Makefile)

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/ruslanmv/Virtual-Webcam-Chatbot.git
cd Virtual-Webcam-Chatbot
```

2. **Install dependencies**

```bash
make install
```

This will:
- Install `uv` if not present
- Create a Python 3.11 virtual environment
- Install all required packages

3. **Configure API keys**

```bash
cp .env.example .env
```

Edit `.env` and add your API keys:

```env
# Required
IBM_SPEECH_TO_TEXT_API=your_ibm_stt_key
IBM_STT_URL=your_ibm_stt_url
OPENAI_API_KEY=your_openai_key

# Optional (Edge TTS is free and enabled by default)
TTS_PROVIDER=edge
```

**Get API keys:**
- **IBM Watson STT**: [IBM Cloud](https://cloud.ibm.com/catalog/services/speech-to-text)
- **OpenAI**: [OpenAI Platform](https://platform.openai.com/api-keys)

4. **Run the application**

```bash
make run
```

---

## ğŸ“– Usage

### Makefile Commands

```bash
make help      # Show all available commands
make install   # Install dependencies with uv
make run       # Run the application (UI mode)
make console   # Run in console mode (no UI)
make dev       # Run in development mode
make test      # Run tests
make clean     # Clean up generated files
make lint      # Run code linting
make format    # Format code
```

### Running the Application

**UI Mode (default):**
```bash
make run
```

**Console Mode:**
```bash
make console
```

**With manual command:**
```bash
uv run python -m meeting_copilot.app
```

### Using the Assistant

1. **Start the application** (listening indicator will show green)
2. **Say the wake word**: "Watson" (or your configured bot name)
3. **Speak your request**:
   - "What did they say about the budget?"
   - "Give me your opinion on this approach"
   - "Summarize the last 2 minutes"
4. **Listen to Watson's response** (spoken and displayed)

### Modes

- **Answer Mode**: Responds to direct questions
- **Opinion Mode**: Provides analysis and perspective
- **Summarize Mode**: Condenses recent conversation

Change modes in the UI dropdown or configure `DEFAULT_MODE` in `.env`.

### Audio Sources

- **Microphone**: Capture your voice
- **System Audio**: Capture meeting audio (Zoom, Teams, etc.)
- **Both**: Capture both microphone and system audio

**Windows Setup for System Audio:**
1. Right-click speaker icon â†’ "Sounds"
2. "Recording" tab â†’ Enable "Stereo Mix"
3. Set as default or select in app

---

## ğŸ—ï¸ Architecture

```
meeting_copilot/
â”œâ”€â”€ audio/                 # Audio processing
â”‚   â”œâ”€â”€ capture_mic.py    # Microphone capture
â”‚   â”œâ”€â”€ capture_loopback.py # System audio capture
â”‚   â”œâ”€â”€ vad.py            # Voice Activity Detection
â”‚   â””â”€â”€ ring_buffer.py    # Pre-wake audio buffer
â”œâ”€â”€ stt/                   # Speech-to-Text
â”‚   â””â”€â”€ watson_stt.py     # IBM Watson STT client
â”œâ”€â”€ wakeword/              # Wake word detection
â”‚   â””â”€â”€ wakeword_text.py  # Text-based wake detection
â”œâ”€â”€ llm/                   # Language model
â”‚   â”œâ”€â”€ client.py         # OpenAI client
â”‚   â””â”€â”€ prompts.py        # System prompts
â”œâ”€â”€ tts/                   # Text-to-Speech
â”‚   â”œâ”€â”€ edge_tts_client.py # Edge TTS (free)
â”‚   â””â”€â”€ ibm_tts.py        # IBM Watson TTS
â”œâ”€â”€ ui/                    # User interface
â”‚   â””â”€â”€ desktop_app.py    # PySide6 UI
â”œâ”€â”€ config.py             # Configuration management
â””â”€â”€ app.py                # Main orchestrator
```

### Audio Pipeline

```
Microphone/System Audio
    â†“
Audio Capture (sounddevice)
    â†“
Ring Buffer (stores last 20s)
    â†“
VAD Segmentation (webrtcvad)
    â†“
Speech-to-Text (IBM Watson)
    â†“
Wake Word Detection (regex on transcript)
    â†“
LLM Processing (OpenAI)
    â†“
Text-to-Speech (Edge TTS)
    â†“
Speaker Output
```

---

## âš™ï¸ Configuration

### Environment Variables

All configuration is done via `.env` file. See `.env.example` for full options.

**Key Settings:**

```env
# Bot Configuration
BOT_NAME=watson                    # Wake word
AUDIO_SOURCE=microphone            # microphone/system/both
DEFAULT_MODE=answer                # answer/opinion/summarize

# Privacy
ENABLE_LOGGING=false               # Opt-in conversation logging
ENCRYPT_LOGS=true                  # Encrypt logs if enabled

# Performance
VAD_AGGRESSIVENESS=2               # 0-3 (higher = more aggressive)
PREWAKE_BUFFER_SECONDS=20         # Context window before wake
LATENCY_TARGET_MS=2500            # Response latency target
```

### TTS Provider

**Edge TTS (Free, Recommended):**
```env
TTS_PROVIDER=edge
EDGE_TTS_VOICE=en-US-GuyNeural
```

**IBM Watson TTS:**
```env
TTS_PROVIDER=ibm
IBM_TTS_API_KEY=your_key
IBM_TTS_URL=your_url
IBM_TTS_VOICE=en-US_AllisonV3Voice
```

---

## ğŸ”’ Privacy & Compliance

### Non-Negotiable Principles

âœ… **User Consent**: Explicit opt-in before audio capture
âœ… **Visual Indicators**: Always show listening status
âœ… **Mute Control**: Instant mute toggle + hotkey
âœ… **Local-First**: Audio processed locally, only transcripts sent to APIs
âœ… **Encryption**: Optional encrypted local logs
âœ… **No Stealth**: Designed for transparent, consensual use

### Data Flow

1. **Audio Capture**: Stays local (not sent to cloud)
2. **Transcription**: Audio sent to IBM Watson STT
3. **LLM Processing**: Transcripts sent to OpenAI
4. **Logs**: Local storage only (opt-in, encrypted)

**No audio is stored** unless logging is explicitly enabled.

---

## ğŸ› ï¸ Development

### Project Structure

- **Python 3.11**: Modern Python with type hints
- **uv**: Fast, reliable package management
- **PySide6**: Cross-platform Qt UI
- **Pydantic**: Settings validation
- **sounddevice**: Low-latency audio I/O

### Adding Dependencies

```bash
uv pip install <package>
uv pip freeze > requirements.txt
```

### Running Tests

```bash
make test
```

### Code Quality

```bash
make lint      # Check code
make format    # Auto-format
```

---

## ğŸ› Troubleshooting

### "No loopback device found"

**Windows:**
1. Open Sound settings
2. Enable "Stereo Mix" in Recording devices
3. Restart application

**Linux/Mac:**
System audio capture is limited. Use virtual audio cable or microphone mode.

### "Watson STT error"

- Verify IBM Watson credentials in `.env`
- Check API key has STT permissions
- Test connection at IBM Cloud console

### "Low audio quality"

- Increase `VAD_AGGRESSIVENESS` (0-3)
- Adjust `VAD_PADDING_MS` for more context
- Use higher quality microphone

### "High latency"

- Switch to Edge TTS (`TTS_PROVIDER=edge`)
- Reduce `PREWAKE_BUFFER_SECONDS`
- Use faster OpenAI model (gpt-3.5-turbo)

---

## ğŸ“¦ Building for Distribution

### Windows Installer (planned)

```bash
make build
```

Creates standalone installer with:
- Bundled Python runtime
- All dependencies
- Auto-update capability
- Desktop shortcuts

---

## ğŸ—ºï¸ Roadmap

### v1.0 (Current)
- âœ… Wake word detection (text-based)
- âœ… Multi-source audio capture
- âœ… Real-time transcription
- âœ… LLM responses
- âœ… TTS playback
- âœ… Desktop UI

### v1.1 (Planned)
- ğŸ”² Real keyword spotting (Porcupine/openWakeWord)
- ğŸ”² Virtual webcam overlay
- ğŸ”² Zoom/Teams integration
- ğŸ”² Custom wake words
- ğŸ”² Multi-language support

### v1.2 (Future)
- ğŸ”² Local LLM option (privacy mode)
- ğŸ”² Meeting analytics
- ğŸ”² Action item extraction
- ğŸ”² macOS/Linux support

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ“„ License

Apache License 2.0 - see LICENSE file for details

---

## ğŸ‘¨â€ğŸ’» Author

**Ruslan Magana**
ğŸ“§ contact@ruslanmv.com
ğŸŒ [ruslanmv.com](https://ruslanmv.com)

---

## ğŸ™ Acknowledgments

- **IBM Watson**: Speech services
- **OpenAI**: Language models
- **Microsoft Edge**: Free TTS service
- **WebRTC VAD**: Voice activity detection

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/ruslanmv/Virtual-Webcam-Chatbot/issues)
- **Email**: contact@ruslanmv.com
- **Documentation**: See `/docs` folder

---

**Built with â¤ï¸ for better meetings**
