{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedce134-b9fc-4698-a7c4-907b4ba516e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "python\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import opuslib\n",
    "from pyogg import OggStreamBufferedEncoder, OggOpusWriter\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "\n",
    "# Initialize\n",
    "audio = pyaudio.PyAudio()\n",
    "vad = webrtcvad.Vad(3)\n",
    "encoder = opuslib.Encoder(RATE, CHANNELS, opuslib.APPLICATION_VOIP)\n",
    "decoder = opuslib.Decoder(RATE, CHANNELS)\n",
    "buffered_encoder = OggStreamBufferedEncoder(OggOpusWriter)\n",
    "\n",
    "# Callback function for playing audio\n",
    "def play_callback(in_data, frame_count, time_info, status):\n",
    "    pcm_data = decoder.decode(in_data)\n",
    "    return (pcm_data, pyaudio.paContinue)\n",
    "\n",
    "# Callback function for recording audio\n",
    "def record_callback(in_data, frame_count, time_info, status):\n",
    "    audio_data = np.frombuffer(in_data, dtype=np.int16)\n",
    "    is_speech = vad.is_speech(audio_data.tobytes(), RATE)\n",
    "\n",
    "    if is_speech:\n",
    "        encoded_data = encoder.encode(audio_data.tobytes(), CHUNK)\n",
    "        buffered_encoder.add_packet(encoded_data)\n",
    "\n",
    "        if buffered_encoder.is_buffer_ready():\n",
    "            ogg_data = buffered_encoder.get_buffer()\n",
    "            stream_out.write(ogg_data)\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Open input and output streams\n",
    "stream_in = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, stream_callback=record_callback)\n",
    "stream_out = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK, stream_callback=play_callback)\n",
    "\n",
    "# Start the streams\n",
    "stream_in.start_stream()\n",
    "stream_out.start_stream()\n",
    "\n",
    "# Keep the script running\n",
    "try:\n",
    "    while stream_in.is_active() and stream_out.is_active():\n",
    "        time.sleep(0.1)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop the streams and clean up\n",
    "stream_in.stop_stream()\n",
    "stream_out.stop_stream()\n",
    "stream_in.close()\n",
    "stream_out.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e62cb6-27be-4f0b-82c2-fb2f199b6492",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Could not find Opus library. Make sure it is installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopuslib\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyogg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OggStreamBufferedEncoder, OggOpusWriter\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\opuslib\\__init__.py:19\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# OpusLib Python Module.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mOpusLib Python Module.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpusError  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OK, APPLICATION_TYPES_MAP  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\opuslib\\exceptions.py:10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mExceptions for OpusLib.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopuslib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\n\u001b[0;32m     12\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mНикита Кузнецов <self@svartalf.info>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m __copyright__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCopyright (c) 2012, SvartalF\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\opuslib\\api\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m lib_location \u001b[38;5;241m=\u001b[39m find_library(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopus\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find Opus library. Make sure it is installed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m libopus \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(lib_location)\n\u001b[0;32m     25\u001b[0m c_int_pointer \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_int)\n",
      "\u001b[1;31mException\u001b[0m: Could not find Opus library. Make sure it is installed."
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import opuslib\n",
    "from pyogg import OggStreamBufferedEncoder, OggOpusWriter\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534852a-d676-416b-8f81-ee752d0a0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "python\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import opuslib\n",
    "from pyogg import OggStreamBufferedEncoder, OggOpusWriter\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "\n",
    "# Initialize\n",
    "audio = pyaudio.PyAudio()\n",
    "encoder = opuslib.Encoder(RATE, CHANNELS, opuslib.APPLICATION_VOIP)\n",
    "decoder = opuslib.Decoder(RATE, CHANNELS)\n",
    "buffered_encoder = OggStreamBufferedEncoder(OggOpusWriter)\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Callback function for playing audio\n",
    "def play_callback(in_data, frame_count, time_info, status):\n",
    "    pcm_data = decoder.decode(in_data)\n",
    "    return (pcm_data, pyaudio.paContinue)\n",
    "\n",
    "# Callback function for recording audio\n",
    "def record_callback(in_data, frame_count, time_info, status):\n",
    "    if is_speech(in_data):\n",
    "        audio_data = np.frombuffer(in_data, dtype=np.int16)\n",
    "        encoded_data = encoder.encode(audio_data.tobytes(), CHUNK)\n",
    "        buffered_encoder.add_packet(encoded_data)\n",
    "\n",
    "        if buffered_encoder.is_buffer_ready():\n",
    "            ogg_data = buffered_encoder.get_buffer()\n",
    "            stream_out.write(ogg_data)\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Open input and output streams\n",
    "stream_in = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, stream_callback=record_callback)\n",
    "stream_out = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK, stream_callback=play_callback)\n",
    "\n",
    "# Start the streams\n",
    "stream_in.start_stream()\n",
    "stream_out.start_stream()\n",
    "\n",
    "# Keep the script running\n",
    "try:\n",
    "    while stream_in.is_active() and stream_out.is_active():\n",
    "        time.sleep(0.1)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop the streams and clean up\n",
    "stream_in.stop_stream()\n",
    "stream_out.stop_stream()\n",
    "stream_in.close()\n",
    "stream_out.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c39a6de-0faa-4ef4-80ec-a9e48134c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a0924-1d32-468e-870c-6ac52f9dd0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40372ed-eb23-4a75-a109-24b8306080b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fbc5c3a-cb61-4c5b-b1bc-3b7544408d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "\n",
    "# Initialize\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Callback function for playing audio\n",
    "def play_callback(in_data, frame_count, time_info, status):\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Callback function for recording audio\n",
    "def record_callback(in_data, frame_count, time_info, status):\n",
    "    if is_speech(in_data):\n",
    "        stream_out.write(in_data)\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Open input and output streams\n",
    "stream_in = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, stream_callback=record_callback)\n",
    "stream_out = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK, stream_callback=play_callback)\n",
    "\n",
    "# Start the streams\n",
    "stream_in.start_stream()\n",
    "stream_out.start_stream()\n",
    "\n",
    "# Keep the script running\n",
    "try:\n",
    "    while stream_in.is_active() and stream_out.is_active():\n",
    "        time.sleep(0.1)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop the streams and clean up\n",
    "stream_in.stop_stream()\n",
    "stream_out.stop_stream()\n",
    "stream_in.close()\n",
    "stream_out.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2699249f-a13c-4dc9-b99e-7156c92e6107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "# Initialize\n",
    "audio = pyaudio.PyAudio()\n",
    "ring_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Callback function for playing audio\n",
    "def play_callback(in_data, frame_count, time_info, status):\n",
    "    if ring_buffer:\n",
    "        return (ring_buffer.popleft(), pyaudio.paContinue)\n",
    "    else:\n",
    "        return (bytes(CHUNK * 2), pyaudio.paContinue)\n",
    "\n",
    "# Callback function for recording audio\n",
    "def record_callback(in_data, frame_count, time_info, status):\n",
    "    voice_detected = is_speech(in_data)\n",
    "    if voice_detected:\n",
    "        print(\"Voice detected\")\n",
    "        ring_buffer.append(in_data)\n",
    "    else:\n",
    "        print(\"No voice detected\")\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Open input and output streams\n",
    "stream_in = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, stream_callback=record_callback)\n",
    "stream_out = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK, stream_callback=play_callback)\n",
    "\n",
    "# Start the streams\n",
    "stream_in.start_stream()\n",
    "stream_out.start_stream()\n",
    "\n",
    "# Keep the script running\n",
    "try:\n",
    "    while stream_in.is_active() and stream_out.is_active():\n",
    "        time.sleep(0.1)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop the streams and clean up\n",
    "stream_in.stop_stream()\n",
    "stream_out.stop_stream()\n",
    "stream_in.close()\n",
    "stream_out.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52fa7362-2694-4c80-8911-74c03f259d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: Microsoft Sound Mapper - Input\n",
      "Device 1: Headset Microphone (Jabra EVOLV\n",
      "Device 2: Microphone Array (IntelÂ® Smart \n",
      "Device 3: Microsoft Sound Mapper - Output\n",
      "Device 4: Headset Earphone (Jabra EVOLVE \n",
      "Device 5: Speakers (Realtek(R) Audio)\n",
      "Device 6: Primary Sound Capture Driver\n",
      "Device 7: Headset Microphone (Jabra EVOLVE 20 MS)\n",
      "Device 8: Microphone Array (IntelÂ® Smart Sound Technology for Digital Microphones)\n",
      "Device 9: Primary Sound Driver\n",
      "Device 10: Headset Earphone (Jabra EVOLVE 20 MS)\n",
      "Device 11: Speakers (Realtek(R) Audio)\n",
      "Device 12: Headset Earphone (Jabra EVOLVE 20 MS)\n",
      "Device 13: Speakers (Realtek(R) Audio)\n",
      "Device 14: Microphone Array (IntelÂ® Smart Sound Technology for Digital Microphones)\n",
      "Device 15: Headset Microphone (Jabra EVOLVE 20 MS)\n",
      "Device 16: Headphones (Realtek HD Audio 2nd output)\n",
      "Device 17: Stereo Mix (Realtek HD Audio Stereo input)\n",
      "Device 18: Speakers (Realtek HD Audio output with SST)\n",
      "Device 19: Microphone (Realtek HD Audio Mic input)\n",
      "Device 20: Microphone Array 1 ()\n",
      "Device 21: Microphone Array 2 ()\n",
      "Device 22: Microphone Array 3 ()\n",
      "Device 23: Headset Microphone (Jabra EVOLVE 20 MS)\n",
      "Device 24: Headset Earphone (Jabra EVOLVE 20 MS)\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "   dev = p.get_device_info_by_index(i)\n",
    "   print(f\"Device {i}: {dev['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b78efd-4af1-423a-8809-563cb9f27f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = p.open(format=pyaudio.paInt16,\n",
    "               channels=1,\n",
    "               rate=44100,\n",
    "               input=True,\n",
    "               input_device_index=1,\n",
    "               frames_per_buffer=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624134c1-59a9-44dd-be5f-efecc521a8a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m vad\u001b[38;5;241m.\u001b[39mset_mode(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Set aggressiveness, 3 is the highest\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Process audio frames with VAD\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m is_speech \u001b[38;5;241m=\u001b[39m vad\u001b[38;5;241m.\u001b[39mis_speech(\u001b[43maudio_frame\u001b[49m, sample_rate)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio_frame' is not defined"
     ]
    }
   ],
   "source": [
    "import webrtcvad\n",
    "\n",
    "vad = webrtcvad.Vad()\n",
    "vad.set_mode(3)  # Set aggressiveness, 3 is the highest\n",
    "\n",
    "# Process audio frames with VAD\n",
    "is_speech = vad.is_speech(audio_frame, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c94e536-2bd0-400f-80a0-7e73b7099797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n",
      "No voice detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "# Initialize\n",
    "audio = pyaudio.PyAudio()\n",
    "ring_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Callback function for playing audio\n",
    "def play_callback(in_data, frame_count, time_info, status):\n",
    "    if ring_buffer:\n",
    "        return (ring_buffer.popleft(), pyaudio.paContinue)\n",
    "    else:\n",
    "        return (bytes(CHUNK * 2), pyaudio.paContinue)\n",
    "\n",
    "# Callback function for recording audio\n",
    "def record_callback(in_data, frame_count, time_info, status):\n",
    "    voice_detected = is_speech(in_data)\n",
    "    if voice_detected:\n",
    "        print(\"Voice detected\")\n",
    "        ring_buffer.append(in_data)\n",
    "    else:\n",
    "        print(\"No voice detected\")\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Open input and output streams\n",
    "stream_in = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, input_device_index=1, frames_per_buffer=CHUNK, stream_callback=record_callback)\n",
    "stream_out = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK, stream_callback=play_callback)\n",
    "\n",
    "# Start the streams\n",
    "stream_in.start_stream()\n",
    "stream_out.start_stream()\n",
    "\n",
    "# Keep the script running\n",
    "try:\n",
    "    while stream_in.is_active() and stream_out.is_active():\n",
    "        time.sleep(0.1)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop the streams and clean up\n",
    "stream_in.stop_stream()\n",
    "stream_out.stop_stream()\n",
    "stream_in.close()\n",
    "stream_out.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31eae14a-e52f-4220-b112-303047a7b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "# Initialize\n",
    "audio = pyaudio.PyAudio()\n",
    "ring_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Callback function for playing audio\n",
    "def play_callback(in_data, frame_count, time_info, status):\n",
    "    if ring_buffer:\n",
    "        return (ring_buffer.popleft(), pyaudio.paContinue)\n",
    "    else:\n",
    "        return (bytes(CHUNK * 2), pyaudio.paContinue)\n",
    "\n",
    "# Callback function for recording audio\n",
    "def record_callback(in_data, frame_count, time_info, status):\n",
    "    if is_speech(in_data):\n",
    "        ring_buffer.append(in_data)\n",
    "\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Open input and output streams\n",
    "stream_in = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK, stream_callback=record_callback)\n",
    "stream_out = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True, frames_per_buffer=CHUNK, stream_callback=play_callback)\n",
    "\n",
    "# Start the streams\n",
    "stream_in.start_stream()\n",
    "stream_out.start_stream()\n",
    "\n",
    "# Keep the script running\n",
    "try:\n",
    "    while stream_in.is_active() and stream_out.is_active():\n",
    "        time.sleep(0.1)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop the streams and clean up\n",
    "stream_in.stop_stream()\n",
    "stream_out.stop_stream()\n",
    "stream_in.close()\n",
    "stream_out.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e90e2d-7b36-438e-a779-00da15501a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Voice detected\n"
     ]
    },
    {
     "ename": "CouldntEncodeError",
     "evalue": "Encoding failed. ffmpeg/avlib returned error code: 3561836632\n\nCommand:['ffmpeg', '-y', '-f', 'wav', '-i', 'C:\\\\Users\\\\066226~1\\\\AppData\\\\Local\\\\Temp\\\\tmptx_8fzl3', '-acodec', 'opus', '-f', 'ogg', 'C:\\\\Users\\\\066226~1\\\\AppData\\\\Local\\\\Temp\\\\tmp6vy1nt5b']\n\nOutput from ffmpeg/avlib:\n\nffmpeg version N-112699-g5a2ca4bf7a-20231108 Copyright (c) 2000-2023 the FFmpeg developers\r\n  built with gcc 13.2.0 (crosstool-NG 1.25.0.232_c175b21)\r\n  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-libxml2 --enable-zlib --enable-libfreetype --enable-libfribidi --enable-gmp --enable-lzma --enable-fontconfig --enable-libharfbuzz --enable-libvorbis --enable-opencl --disable-libpulse --enable-libvmaf --disable-libxcb --disable-xlib --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-lv2 --enable-libvpl --enable-openal --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-vulkan --enable-libshaderc --enable-libplacebo --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-ldflags=-pthread --extra-ldexeflags= --extra-libs=-lgomp --extra-version=20231108\r\n  libavutil      58. 31.100 / 58. 31.100\r\n  libavcodec     60. 33.100 / 60. 33.100\r\n  libavformat    60. 17.100 / 60. 17.100\r\n  libavdevice    60.  4.100 / 60.  4.100\r\n  libavfilter     9. 13.100 /  9. 13.100\r\n  libswscale      7.  6.100 /  7.  6.100\r\n  libswresample   4. 13.100 /  4. 13.100\r\n  libpostproc    57.  4.100 / 57.  4.100\r\n[aist#0:0/pcm_s16le @ 0000027521827f80] Guessed Channel Layout: mono\r\nInput #0, wav, from 'C:\\Users\\066226~1\\AppData\\Local\\Temp\\tmptx_8fzl3':\r\n  Duration: 00:00:05.00, bitrate: 256 kb/s\r\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (pcm_s16le (native) -> opus (native))\r\nPress [q] to stop, [?] for help\r\n[opus @ 000002752184f480] The encoder 'opus' is experimental but experimental codecs are not enabled, add '-strict -2' if you want to use it.\r\n[opus @ 000002752184f480] Alternatively use the non experimental encoder 'libopus'.\r\nError while filtering: Experimental feature\r\n[out#0/ogg @ 00000275217ba0c0] Nothing was written into output file, because at least one of its streams received no packets.\r\nsize=       0kB time=N/A bitrate=N/A speed=N/A    \r\nConversion failed!\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCouldntEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo voice detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 57\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_speech(audio_segment\u001b[38;5;241m.\u001b[39mraw_data):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoice detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m     opus_audio_segment \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_opus\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# You can now use opus_audio_segment for further processing\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo voice detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 45\u001b[0m, in \u001b[0;36mconvert_to_opus\u001b[1;34m(audio_segment)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_opus\u001b[39m(audio_segment):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mas\u001b[39;00m byte_stream:\n\u001b[1;32m---> 45\u001b[0m         \u001b[43maudio_segment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mogg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m         byte_stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     47\u001b[0m         opus_audio_segment \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_file(byte_stream, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mogg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\pydub\\audio_segment.py:970\u001b[0m, in \u001b[0;36mAudioSegment.export\u001b[1;34m(self, out_f, format, codec, bitrate, parameters, tags, id3v2_version, cover)\u001b[0m\n\u001b[0;32m    967\u001b[0m log_subprocess_output(p_err)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CouldntEncodeError(\n\u001b[0;32m    971\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding failed. ffmpeg/avlib returned error code: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCommand:\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutput from ffmpeg/avlib:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    972\u001b[0m             p\u001b[38;5;241m.\u001b[39mreturncode, conversion_command, p_err\u001b[38;5;241m.\u001b[39mdecode(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m) ))\n\u001b[0;32m    974\u001b[0m output\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    975\u001b[0m out_f\u001b[38;5;241m.\u001b[39mwrite(output\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[1;31mCouldntEncodeError\u001b[0m: Encoding failed. ffmpeg/avlib returned error code: 3561836632\n\nCommand:['ffmpeg', '-y', '-f', 'wav', '-i', 'C:\\\\Users\\\\066226~1\\\\AppData\\\\Local\\\\Temp\\\\tmptx_8fzl3', '-acodec', 'opus', '-f', 'ogg', 'C:\\\\Users\\\\066226~1\\\\AppData\\\\Local\\\\Temp\\\\tmp6vy1nt5b']\n\nOutput from ffmpeg/avlib:\n\nffmpeg version N-112699-g5a2ca4bf7a-20231108 Copyright (c) 2000-2023 the FFmpeg developers\r\n  built with gcc 13.2.0 (crosstool-NG 1.25.0.232_c175b21)\r\n  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-libxml2 --enable-zlib --enable-libfreetype --enable-libfribidi --enable-gmp --enable-lzma --enable-fontconfig --enable-libharfbuzz --enable-libvorbis --enable-opencl --disable-libpulse --enable-libvmaf --disable-libxcb --disable-xlib --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-lv2 --enable-libvpl --enable-openal --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-vulkan --enable-libshaderc --enable-libplacebo --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-ldflags=-pthread --extra-ldexeflags= --extra-libs=-lgomp --extra-version=20231108\r\n  libavutil      58. 31.100 / 58. 31.100\r\n  libavcodec     60. 33.100 / 60. 33.100\r\n  libavformat    60. 17.100 / 60. 17.100\r\n  libavdevice    60.  4.100 / 60.  4.100\r\n  libavfilter     9. 13.100 /  9. 13.100\r\n  libswscale      7.  6.100 /  7.  6.100\r\n  libswresample   4. 13.100 /  4. 13.100\r\n  libpostproc    57.  4.100 / 57.  4.100\r\n[aist#0:0/pcm_s16le @ 0000027521827f80] Guessed Channel Layout: mono\r\nInput #0, wav, from 'C:\\Users\\066226~1\\AppData\\Local\\Temp\\tmptx_8fzl3':\r\n  Duration: 00:00:05.00, bitrate: 256 kb/s\r\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\r\nStream mapping:\r\n  Stream #0:0 -> #0:0 (pcm_s16le (native) -> opus (native))\r\nPress [q] to stop, [?] for help\r\n[opus @ 000002752184f480] The encoder 'opus' is experimental but experimental codecs are not enabled, add '-strict -2' if you want to use it.\r\n[opus @ 000002752184f480] Alternatively use the non experimental encoder 'libopus'.\r\nError while filtering: Experimental feature\r\n[out#0/ogg @ 00000275217ba0c0] Nothing was written into output file, because at least one of its streams received no packets.\r\nsize=       0kB time=N/A bitrate=N/A speed=N/A    \r\nConversion failed!\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Record audio using sounddevice\n",
    "def record_audio():\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(frames=RECORD_SECONDS * RATE, samplerate=RATE, channels=CHANNELS, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data\n",
    "\n",
    "# Save recorded audio to a temporary WAV file and read it as a byte stream\n",
    "def save_to_byte_stream(audio_data):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        with sf.SoundFile(byte_stream, 'w', samplerate=RATE, channels=CHANNELS, format='WAV', subtype='PCM_16') as wav_file:\n",
    "            wav_file.write(audio_data)\n",
    "        byte_stream.seek(0)\n",
    "        audio_segment = AudioSegment.from_file(byte_stream, format=\"wav\")\n",
    "    return audio_segment\n",
    "\n",
    "# Convert audio to OGG format with Opus codec\n",
    "def convert_to_opus(audio_segment):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        audio_segment.export(byte_stream, format=\"ogg\", codec=\"opus\")\n",
    "        byte_stream.seek(0)\n",
    "        opus_audio_segment = AudioSegment.from_file(byte_stream, format=\"ogg\")\n",
    "    return opus_audio_segment\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    audio_data = record_audio()\n",
    "    audio_segment = save_to_byte_stream(audio_data)\n",
    "\n",
    "    if is_speech(audio_segment.raw_data):\n",
    "        print(\"Voice detected\")\n",
    "        opus_audio_segment = convert_to_opus(audio_segment)\n",
    "        # You can now use opus_audio_segment for further processing\n",
    "    else:\n",
    "        print(\"No voice detected\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41905b0d-3bfe-4204-87f2-2d1ecf4c4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Voice detected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "# Record audio using sounddevice\n",
    "def record_audio():\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(frames=RECORD_SECONDS * RATE, samplerate=RATE, channels=CHANNELS, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data\n",
    "\n",
    "# Save recorded audio to a temporary WAV file and read it as a byte stream\n",
    "def save_to_byte_stream(audio_data):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        with sf.SoundFile(byte_stream, 'w', samplerate=RATE, channels=CHANNELS, format='WAV', subtype='PCM_16') as wav_file:\n",
    "            wav_file.write(audio_data)\n",
    "        byte_stream.seek(0)\n",
    "        audio_segment = AudioSegment.from_file(byte_stream, format=\"wav\")\n",
    "    return audio_segment\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    audio_data = record_audio()\n",
    "    audio_segment = save_to_byte_stream(audio_data)\n",
    "\n",
    "    if is_speech(audio_segment.raw_data):\n",
    "        print(\"Voice detected\")\n",
    "        # You can now use audio_segment for further processing\n",
    "    else:\n",
    "        print(\"No voice detected\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28f51fa2-8794-46b4-b866-a3587bf55748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Voice detected\n",
      "Playing audio...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "# Detect if there's voice activity\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Record audio using sounddevice\n",
    "def record_audio():\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(frames=RECORD_SECONDS * RATE, samplerate=RATE, channels=CHANNELS, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data\n",
    "\n",
    "# Save recorded audio to a temporary WAV file and read it as a byte stream\n",
    "def save_to_byte_stream(audio_data):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        with sf.SoundFile(byte_stream, 'w', samplerate=RATE, channels=CHANNELS, format='WAV', subtype='PCM_16') as wav_file:\n",
    "            wav_file.write(audio_data)\n",
    "        byte_stream.seek(0)\n",
    "        audio_segment = AudioSegment.from_file(byte_stream, format=\"wav\")\n",
    "    return audio_segment\n",
    "\n",
    "# Play audio using sounddevice\n",
    "def play_audio(audio_segment):\n",
    "    print(\"Playing audio...\")\n",
    "    audio_data = np.array(audio_segment.get_array_of_samples(), dtype=np.int16)\n",
    "    sd.play(audio_data, samplerate=RATE)\n",
    "    sd.wait()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    audio_data = record_audio()\n",
    "    audio_segment = save_to_byte_stream(audio_data)\n",
    "\n",
    "    if is_speech(audio_segment.raw_data):\n",
    "        print(\"Voice detected\")\n",
    "        play_audio(audio_segment)\n",
    "    else:\n",
    "        print(\"No voice detected\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f6c3fa-6f68-4789-92cd-5f4cae1db8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Voice detected\n",
      "Playing audio...\n",
      "Recording...\n",
      "Voice detected\n",
      "Playing audio...\n",
      "Recording...\n",
      "Voice detected\n",
      "Playing audio...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Optional: Add a short delay between iterations\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 47\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m         audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m         audio_segment \u001b[38;5;241m=\u001b[39m save_to_byte_stream(audio_data)\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_speech(audio_segment\u001b[38;5;241m.\u001b[39mraw_data):\n",
      "Cell \u001b[1;32mIn[21], line 28\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(frames\u001b[38;5;241m=\u001b[39mRECORD_SECONDS \u001b[38;5;241m*\u001b[39m RATE, samplerate\u001b[38;5;241m=\u001b[39mRATE, channels\u001b[38;5;241m=\u001b[39mCHANNELS, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m audio_data\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def record_audio():\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(frames=RECORD_SECONDS * RATE, samplerate=RATE, channels=CHANNELS, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data\n",
    "\n",
    "def save_to_byte_stream(audio_data):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        with sf.SoundFile(byte_stream, 'w', samplerate=RATE, channels=CHANNELS, format='WAV', subtype='PCM_16') as wav_file:\n",
    "            wav_file.write(audio_data)\n",
    "        byte_stream.seek(0)\n",
    "        audio_segment = AudioSegment.from_file(byte_stream, format=\"wav\")\n",
    "    return audio_segment\n",
    "\n",
    "def play_audio(audio_segment):\n",
    "    print(\"Playing audio...\")\n",
    "    audio_data = np.array(audio_segment.get_array_of_samples(), dtype=np.int16)\n",
    "    sd.play(audio_data, samplerate=RATE)\n",
    "    sd.wait()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        audio_data = record_audio()\n",
    "        audio_segment = save_to_byte_stream(audio_data)\n",
    "\n",
    "        if is_speech(audio_segment.raw_data):\n",
    "            print(\"Voice detected\")\n",
    "            play_audio(audio_segment)\n",
    "        #else:\n",
    "        #    print(\"No voice detected\")\n",
    "        time.sleep(0.5)  # Optional: Add a short delay between iterations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c001fe2-bfb3-4517-8a3b-6bc30754ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Optional: Add a short delay between iterations\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 50\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m recording \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     audio_segment \u001b[38;5;241m=\u001b[39m save_to_byte_stream(audio_data)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_speech(audio_segment\u001b[38;5;241m.\u001b[39mraw_data):\n",
      "Cell \u001b[1;32mIn[31], line 27\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m():\n\u001b[0;32m     26\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(RECORD_SECONDS \u001b[38;5;241m*\u001b[39m RATE), samplerate\u001b[38;5;241m=\u001b[39mRATE, channels\u001b[38;5;241m=\u001b[39mCHANNELS, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio_data\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "RECORD_SECONDS = 0.7  # Record in smaller chunks\n",
    "\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def record_audio():\n",
    "    audio_data = sd.rec(frames=int(RECORD_SECONDS * RATE), samplerate=RATE, channels=CHANNELS, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data\n",
    "\n",
    "def save_to_byte_stream(audio_data):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        with sf.SoundFile(byte_stream, 'w', samplerate=RATE, channels=CHANNELS, format='WAV', subtype='PCM_16') as wav_file:\n",
    "            wav_file.write(audio_data)\n",
    "        byte_stream.seek(0)\n",
    "        audio_segment = AudioSegment.from_file(byte_stream, format=\"wav\")\n",
    "    return audio_segment\n",
    "\n",
    "def play_audio(audio_segment):\n",
    "    print(\"Playing audio...\")\n",
    "    audio_data = np.array(audio_segment.get_array_of_samples(), dtype=np.int16)\n",
    "    sd.play(audio_data, samplerate=RATE)\n",
    "    sd.wait()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        recorded_audio = AudioSegment.empty()\n",
    "        recording = False\n",
    "\n",
    "        while True:\n",
    "            audio_data = record_audio()\n",
    "            audio_segment = save_to_byte_stream(audio_data)\n",
    "\n",
    "            if is_speech(audio_segment.raw_data):\n",
    "                if not recording:\n",
    "                    print(\"Voice detected\")\n",
    "                    recording = True\n",
    "                recorded_audio += audio_segment\n",
    "            else:\n",
    "                if recording:\n",
    "                    print(\"Silence detected\")\n",
    "                    break\n",
    "\n",
    "        if len(recorded_audio) > 0:\n",
    "            play_audio(recorded_audio)\n",
    "        #else:\n",
    "        #    print(\"No voice detected\")\n",
    "\n",
    "        time.sleep(0.5)  # Optional: Add a short delay between iterations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d7bfc1-355f-44bb-b0c4-943955016720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Optional: Add a short delay between iterations\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 52\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m silence_start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     audio_segment \u001b[38;5;241m=\u001b[39m save_to_byte_stream(audio_data)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_speech(audio_segment\u001b[38;5;241m.\u001b[39mraw_data):\n",
      "Cell \u001b[1;32mIn[26], line 28\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m():\n\u001b[0;32m     27\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(RECORD_SECONDS \u001b[38;5;241m*\u001b[39m RATE), samplerate\u001b[38;5;241m=\u001b[39mRATE, channels\u001b[38;5;241m=\u001b[39mCHANNELS, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio_data\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "689b720c-e6bc-456a-bf4c-b3ca10def37f",
   "metadata": {},
   "source": [
    "The issue of the last words or ending sounds being dropped during audio playback could be due to a combination of factors, including the way audio is recorded in smaller chunks, the silence detection method, and the specific recording setup. Here are some possible explanations and suggestions to improve the audio playback:\r\n",
    "\r\n",
    "1. Incomplete recording of the last chunk: The last chunk of audio might not contain the complete ending sound or word, causing it to be cut off during playback. You can try increasing the `RECORD_SECONDS` value to record longer chunks, which might help capture the complete ending sound.\r\n",
    "\r\n",
    "2. Silence detection threshold: The `SILENCE_THRESHOLD` and `REQUIRED_NONSILENT` values used in the `is_speech` function might be too strict, causing the last part of the speech to be considered as silence. You can try adjusting these values to better suit your specific recording environment and setup.\r\n",
    "\r\n",
    "3. Insufficient padding after detecting silence: The code stops recording as soon as silence is detected, which might cause the last sound to be cut off. To address this, you can add a short padding time after detecting silence, as demonstrated in the previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2292dea-e8d1-4373-b807-9b9ca157b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here is the full code of the modified solution with increased `RECORD_SECONDS` and added `SILENCE_PADDING_TIME`:\n",
    "\n",
    "\n",
    "This modified solution records audio in longer chunks of 1 second and adds a 0.5-second padding time after detecting silence to ensure the entire speech, including the ending sounds, is captured. You can further fine-tune the parameters based on your specific recording environment and setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a257303b-bbeb-4611-b7e4-1e87527d7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;66;03m#time.sleep(0.5)  # Optional: Add a short delay between iterations\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 52\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m silence_start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     audio_segment \u001b[38;5;241m=\u001b[39m save_to_byte_stream(audio_data)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_speech(audio_segment\u001b[38;5;241m.\u001b[39mraw_data):\n",
      "Cell \u001b[1;32mIn[34], line 28\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m():\n\u001b[0;32m     27\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(RECORD_SECONDS \u001b[38;5;241m*\u001b[39m RATE), samplerate\u001b[38;5;241m=\u001b[39mRATE, channels\u001b[38;5;241m=\u001b[39mCHANNELS, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio_data\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 480\n",
    "SILENCE_THRESHOLD = -50\n",
    "REQUIRED_NONSILENT = 100\n",
    "RECORD_SECONDS = 1.0  # Record in longer chunks\n",
    "SILENCE_PADDING_TIME = 0.5  # Time to keep recording after silence is detected\n",
    "\n",
    "def is_speech(audio_data):\n",
    "    audio_segment = AudioSegment(audio_data, sample_width=2, channels=CHANNELS, frame_rate=RATE)\n",
    "    nonsilent_ranges = detect_nonsilent(audio_segment, min_silence_len=100, silence_thresh=SILENCE_THRESHOLD)\n",
    "\n",
    "    if nonsilent_ranges and nonsilent_ranges[-1][1] - nonsilent_ranges[0][0] >= REQUIRED_NONSILENT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def record_audio():\n",
    "    audio_data = sd.rec(frames=int(RECORD_SECONDS * RATE), samplerate=RATE, channels=CHANNELS, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data\n",
    "\n",
    "def save_to_byte_stream(audio_data):\n",
    "    with io.BytesIO() as byte_stream:\n",
    "        with sf.SoundFile(byte_stream, 'w', samplerate=RATE, channels=CHANNELS, format='WAV', subtype='PCM_16') as wav_file:\n",
    "            wav_file.write(audio_data)\n",
    "        byte_stream.seek(0)\n",
    "        audio_segment = AudioSegment.from_file(byte_stream, format=\"wav\")\n",
    "    return audio_segment\n",
    "\n",
    "def play_audio(audio_segment):\n",
    "    print(\"Playing audio...\")\n",
    "    audio_data = np.array(audio_segment.get_array_of_samples(), dtype=np.int16)\n",
    "    sd.play(audio_data, samplerate=RATE)\n",
    "    sd.wait()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        recorded_audio = AudioSegment.empty()\n",
    "        recording = False\n",
    "        silence_start_time = None\n",
    "\n",
    "        while True:\n",
    "            audio_data = record_audio()\n",
    "            audio_segment = save_to_byte_stream(audio_data)\n",
    "\n",
    "            if is_speech(audio_segment.raw_data):\n",
    "                if not recording:\n",
    "                    print(\"Voice detected\")\n",
    "                    recording = True\n",
    "                recorded_audio += audio_segment\n",
    "                silence_start_time = None\n",
    "            else:\n",
    "                if recording:\n",
    "                    if silence_start_time is None:\n",
    "                        silence_start_time = time.time()\n",
    "                    elif time.time() - silence_start_time >= SILENCE_PADDING_TIME:\n",
    "                        print(\"Silence detected\")\n",
    "                        break\n",
    "\n",
    "        if len(recorded_audio) > 0:\n",
    "            play_audio(recorded_audio)\n",
    "        else:\n",
    "            print(\"No voice detected\")\n",
    "\n",
    "        #time.sleep(0.5)  # Optional: Add a short delay between iterations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b387580-de91-4757-a64b-b66be7313e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n",
      "Voice detected\n",
      "Silence detected\n",
      "Playing audio...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Optional: Add a short delay between iterations\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 50\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m recording \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     audio_segment \u001b[38;5;241m=\u001b[39m save_to_byte_stream(audio_data)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_speech(audio_segment\u001b[38;5;241m.\u001b[39mraw_data):\n",
      "Cell \u001b[1;32mIn[35], line 27\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m():\n\u001b[0;32m     26\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(RECORD_SECONDS \u001b[38;5;241m*\u001b[39m RATE), samplerate\u001b[38;5;241m=\u001b[39mRATE, channels\u001b[38;5;241m=\u001b[39mCHANNELS, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m audio_data\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Blog\\Virtual-Webcam-Chatbot\\.venv\\lib\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900dc7d-8311-4fff-8d73-6009b4e1dab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (watson)",
   "language": "python",
   "name": "watson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
